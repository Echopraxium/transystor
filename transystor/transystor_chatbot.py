"""
TranSysTor Chatbot Module
Assistant IA pour validation et critique
"""


def create_chatbot_interface(state):
    """
    Cr√©e l'interface du chatbot
    
    Args:
        state: Instance de IDEState
    
    Returns:
        Tuple (provider_widget, api_key_widget, chat_input, chat_button, chat_output)
    """
    import ipywidgets as widgets
    from IPython.display import clear_output
    
    # Widgets
    chatbot_provider = widgets.Dropdown(
        options=['Anthropic (Claude)', 'OpenAI (GPT)', 'Local (Ollama)', 'D√©sactiv√©'],
        value='D√©sactiv√©',
        description='Provider:',
        style={'description_width': 'initial'}
    )
    
    api_key_input = widgets.Password(
        placeholder='Entrez votre cl√© API',
        description='API Key:',
        disabled=True,
        style={'description_width': 'initial'}
    )
    
    chat_input = widgets.Textarea(
        placeholder='Posez votre question sur le framework TSCP...',
        description='Question:',
        layout=widgets.Layout(width='100%', height='100px')
    )
    
    chat_button = widgets.Button(
        description='Envoyer',
        button_style='info',
        icon='paper-plane',
        disabled=True
    )
    
    chat_output = widgets.Output()
    
    # Callbacks
    def on_provider_change(change):
        if change['new'] in ['Anthropic (Claude)', 'OpenAI (GPT)']:
            api_key_input.disabled = False
            chat_button.disabled = False
        elif change['new'] == 'Local (Ollama)':
            api_key_input.disabled = True
            chat_button.disabled = False
        else:
            api_key_input.disabled = True
            chat_button.disabled = True
        
        state.chatbot_config['provider'] = change['new']
    
    chatbot_provider.observe(on_provider_change, names='value')
    
    def on_chat_send(b):
        with chat_output:
            clear_output(wait=True)
            
            question = chat_input.value
            if not question:
                print("‚ö†Ô∏è Veuillez entrer une question")
                return
            
            print(f"üí¨ Vous: {question}\n")
            print("ü§ñ Assistant:\n")
            
            provider = chatbot_provider.value
            
            if provider == 'Anthropic (Claude)':
                response = send_to_anthropic(question, api_key_input.value, state)
                print(response)
            
            elif provider == 'OpenAI (GPT)':
                response = send_to_openai(question, api_key_input.value, state)
                print(response)
            
            elif provider == 'Local (Ollama)':
                response = send_to_ollama(question, state)
                print(response)
            
            else:
                print("Chatbot d√©sactiv√©")
    
    chat_button.on_click(on_chat_send)
    
    return chatbot_provider, api_key_input, chat_input, chat_button, chat_output


def send_to_anthropic(question, api_key, state):
    """
    Envoie une question √† l'API Anthropic
    
    Args:
        question: Question de l'utilisateur
        api_key: Cl√© API
        state: Instance de IDEState
    
    Returns:
        R√©ponse du mod√®le
    """
    if not api_key:
        return "‚ùå Veuillez configurer votre cl√© API Anthropic"
    
    try:
        import anthropic
        
        client = anthropic.Anthropic(api_key=api_key)
        
        system_prompt = """Tu es un expert du framework TSCP (Principes Transdisciplinaires de Construction de Syst√®mes).

Le framework TSCP organise les principes en 4 couches :
- CM0 : Meta-m√©tamod√®le (plan 5√ó5) - Meta-metaclasses et M√©ta-traits
- CM1 : M√©tamod√®le (cube 3√ó3√ó3) - Metaclasses et Traits
- CM2 : Mod√®le (cube 4√ó4√ó4) - Classes organis√©es dans un cube
- CM3 : Syst√®mes r√©els (cube 5√ó5√ó5) - Instances concr√®tes

Op√©rateurs :
- ‚äó : Produit tensoriel (combinaison)
- ‚àà : Instance de
- ‚äÇ : Sous-classe de / D√©rive de

Ton r√¥le : valider les principes, d√©tecter les incoh√©rences, proposer des am√©liorations, v√©rifier l'orthogonalit√©."""
        
        message = client.messages.create(
            model=state.chatbot_config['model'],
            max_tokens=1000,
            system=system_prompt,
            messages=[
                {"role": "user", "content": question}
            ]
        )
        
        return message.content[0].text
        
    except ImportError:
        return """‚ùå Module 'anthropic' non install√©.

Pour installer :
    pip install anthropic

Puis relancez cette cellule."""
    
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"


def send_to_openai(question, api_key, state):
    """
    Envoie une question √† l'API OpenAI
    
    Args:
        question: Question de l'utilisateur
        api_key: Cl√© API
        state: Instance de IDEState
    
    Returns:
        R√©ponse du mod√®le
    """
    if not api_key:
        return "‚ùå Veuillez configurer votre cl√© API OpenAI"
    
    try:
        import openai
        
        openai.api_key = api_key
        
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Tu es un expert du framework TSCP."},
                {"role": "user", "content": question}
            ]
        )
        
        return response.choices[0].message.content
        
    except ImportError:
        return """‚ùå Module 'openai' non install√©.

Pour installer :
    pip install openai

Puis relancez cette cellule."""
    
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"


def send_to_ollama(question, state):
    """
    Envoie une question √† Ollama local
    
    Args:
        question: Question de l'utilisateur
        state: Instance de IDEState
    
    Returns:
        R√©ponse du mod√®le
    """
    try:
        import ollama
        
        response = ollama.chat(model='llama2', messages=[
            {'role': 'system', 'content': 'Tu es un expert du framework TSCP.'},
            {'role': 'user', 'content': question}
        ])
        
        return response['message']['content']
        
    except ImportError:
        return """‚ùå Module 'ollama' non install√©.

Pour installer :
    pip install ollama

Assurez-vous √©galement que le serveur Ollama est lanc√© localement."""
    
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"


def get_predefined_questions():
    """
    Retourne une liste de questions pr√©d√©finies
    
    Returns:
        Liste de tuples (label, question)
    """
    return [
        ("V√©rifier orthogonalit√©", "V√©rifie l'orthogonalit√© de tous les principes de CM2 et identifie les conflits potentiels."),
        ("Proposer contre-arguments", "Propose 3 contre-arguments pour ranger 'M√©tabolisme' en CM1 plut√¥t qu'en CM2."),
        ("D√©pendances manquantes", "Quelles sont les d√©pendances manquantes pour que le principe 'Communication' soit complet ?"),
        ("Formule tensorielle", "G√©n√®re une formule tensorielle pour combiner 'Agent' et 'Comportement'."),
        ("Validation isotopie", "Est-ce que 'Sym√©trie/Asym√©trie' forme une isotopie valide ? Justifie."),
        ("Restructuration sugg√©r√©e", "Analyse la structure actuelle du cube CM2 et propose des am√©liorations."),
    ]


print("‚úÖ Module TranSysTor Chatbot charg√©")